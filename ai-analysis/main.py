#!/usr/bin/env python3
"""Main entry point for AI Test Analysis Pipeline."""

import argparse
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from config import settings


def run_api(host: str = None, port: int = None):
    """Run the FastAPI server."""
    import uvicorn
    from src.api import app
    
    uvicorn.run(
        app,
        host=host or settings.API_HOST,
        port=port or settings.API_PORT,
        reload=False,
    )


def run_analysis():
    """Run analysis on current logs and print summary."""
    from src.analysis_service import AnalysisService
    
    print(f"\nğŸ“Š AI Test Analysis Pipeline")
    print(f"{'=' * 50}")
    print(f"Log file: {settings.LOGS_PATH}")
    
    if not settings.LOGS_PATH.exists():
        print(f"\nâŒ Log file not found: {settings.LOGS_PATH}")
        print("Run tests first: ./mvnw clean test")
        return
    
    service = AnalysisService()
    
    # Load and index
    print(f"\nğŸ“¥ Loading and indexing logs...")
    stats = service.load_and_index()
    
    print(f"\nğŸ“ˆ Index Statistics:")
    print(f"  Total events: {stats['total_events']}")
    print(f"  Tests passed: {stats['passed']}")
    print(f"  Failures indexed: {stats['failures_indexed']}")
    
    # Get summary
    summary = service.get_summary()
    
    print(f"\nğŸ“‹ Failure Summary:")
    print(f"  Total tests: {summary['total_tests']}")
    print(f"  Total failures: {summary['total_failures']}")
    print(f"  Failure rate: {summary['failure_rate']:.1f}%")
    
    if summary['failures_by_test']:
        print(f"\nğŸ”´ Failures by Test:")
        for test, count in summary['failures_by_test'].items():
            print(f"  - {test}: {count}")
    
    # Analyze each failure
    from src.log_parser import LogParser
    parser = LogParser(settings.LOGS_PATH)
    failures = parser.get_failures()
    
    if failures:
        print(f"\nğŸ” Detailed Analysis:")
        for failure in failures:
            print(f"\n{'â”€' * 50}")
            analysis = service.analyze_failure(failure)
            print(f"Test: {analysis['test_name']}")
            print(f"Class: {analysis['class_name']}")
            print(f"Error: {analysis['error_message'][:100]}...")
            print(f"\nğŸ’¡ Recommendation:")
            print(f"  {analysis['recommendation']}")
            
            if analysis['similar_failures']:
                print(f"\nğŸ“ Similar Failures Found: {len(analysis['similar_failures'])}")
    
    print(f"\n{'=' * 50}")
    print(f"âœ… Analysis complete!")
    print(f"\nTo start the API server, run:")
    print(f"  python main.py serve")


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="AI Test Analysis Pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    subparsers = parser.add_subparsers(dest="command", help="Commands")
    
    # Serve command
    serve_parser = subparsers.add_parser("serve", help="Start the API server")
    serve_parser.add_argument("--host", default="0.0.0.0", help="Host to bind")
    serve_parser.add_argument("--port", type=int, default=8000, help="Port to bind")
    
    # Analyze command
    analyze_parser = subparsers.add_parser("analyze", help="Run analysis on logs")
    
    args = parser.parse_args()
    
    if args.command == "serve":
        print(f"ğŸš€ Starting AI Test Analysis API at http://{args.host}:{args.port}")
        print(f"ğŸ“š API docs at http://localhost:{args.port}/docs")
        run_api(args.host, args.port)
    elif args.command == "analyze":
        run_analysis()
    else:
        # Default: run analysis
        run_analysis()


if __name__ == "__main__":
    main()

